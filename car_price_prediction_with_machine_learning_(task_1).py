# -*- coding: utf-8 -*-
"""Car Price Prediction with Machine Learning (task 1)

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1EJmgHF8c-lje8HeFuXSaOeRP9G6e9xcC
"""

# import basic libraries

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

plt.boxplot(data["Price"])
plt.show()

sns.histplot(data['Price'], bins=50)
plt.show()

# import data set

data = pd.read_csv("car_price_prediction.csv")

# Remove cars with Price < 1000
data = data[data['Price'] >= 1000].reset_index(drop=True)


data.head()

data.tail()

data.info()

data.describe()

data.shape

# replace "-" with mean value of column.

data["Levy"] = data["Levy"].replace("-", np.nan)

data["Levy"] = pd.to_numeric(data["Levy"], errors='coerce')

data["Levy"] = data["Levy"].fillna(data["Levy"].mean())

data.head()

# drop columns

data = data.drop(["ID", "Doors", "Model", "Leather interior"], axis = 1)

data.head()



# replacing "km" to "" in Mileage columna and convert it to numeric

data["Mileage"] = data["Mileage"].str.replace(" km", "")
data["Mileage"] = pd.to_numeric(data["Mileage"])

# replacing "Turbo" to "" in Engine volume columna and convert it to numeric

data["Engine volume"] = data["Engine volume"].str.replace(" Turbo", "")
data["Engine volume"] = pd.to_numeric(data["Engine volume"])

# check null values

data.isnull().sum()

# Find all rows that contain at least one null value

data[data.isnull().any(axis=1)]

# Find rows with null in a specific column

data[data["Drive wheels"].isnull()]

# Get index numbers of rows with null values

data[data.isnull().any(axis=1)].index

# Count how many rows contain null values

data.isnull().any(axis=1).sum()



# fill missing values with mode in case of categorical data and with mean in case of numerical data.

data["Drive wheels"] = data["Drive wheels"].fillna(data["Drive wheels"].mode()[0])

data["Wheel"] = data["Wheel"].fillna(data["Wheel"].mode()[0])

data["Color"] = data["Color"].fillna(data["Color"].mode()[0])

data["Airbags"] = data["Airbags"].fillna(data["Airbags"].mean())

data.isnull().sum()

# add new column
# current year is 2025
data['Car_age'] = 2025 - data['Prod. year']

data.info()

data["Manufacturer"].value_counts()





# split data into dependent and independent variables

x = data.drop("Price", axis = 1)
y = data[["Price"]]   # .values =>  converts to NumPy array.

y.describe()

y = np.log1p(data["Price"])

print(type(x))

print(type(y))

# train test split

from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.4, random_state = 0)



# incoding categorical variables and scaling numerical variables.

from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.compose import ColumnTransformer

categorical_columns = ["Manufacturer", "Category", "Fuel type",
                       "Gear box type", "Drive wheels", "Wheel", "Color"]

numerical_columns = ["Levy", "Prod. year", "Engine volume", "Mileage", "Cylinders","Airbags", "Car_age"]

ct = ColumnTransformer(transformers = [("num", StandardScaler(), numerical_columns),
                                       ("encoder", OneHotEncoder(drop = "first", handle_unknown = "ignore"), categorical_columns)], remainder = "drop")

x_train = ct.fit_transform(x_train)
x_test = ct.transform(x_test)



# built multiple linear regression model

from sklearn.linear_model import LinearRegression
regressor = LinearRegression()
regressor.fit(x_train, y_train)

# prediction
y_pred = regressor.predict(x_test)
print(y_pred)

# final y value

y_true = np.expm1(y_pred)
print(y_true)

# coefficint and intercept

print(regressor.coef_)

print(regressor.intercept_)

# model evaluation

from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error
import numpy as np

r2 = r2_score(y_test, y_pred)
mae = mean_absolute_error(y_test, y_pred)
mse = mean_squared_error(y_test, y_pred)
rmse = np.sqrt(mse)

print("RÂ² Score:", r2)
print("MAE:", mae)
print("MSE:", mse)
print("RMSE:", rmse)

import numpy as np

# Approximate interpretation in original price
mae_original = np.expm1(1.017)  #  1.017 ---> 1.76 times original scale
rmse_original = np.expm1(1.429)  # 3.17 times
print(mae_original)
print(rmse_original)





# random forest regression

from sklearn.ensemble import RandomForestRegressor

rf = RandomForestRegressor(
    n_estimators=500,
    max_depth=20,
    min_samples_leaf=3,
    random_state=42,
    n_jobs=-1
)


rf.fit(x_train, y_train)
y_pred = rf.predict(x_test)

from sklearn.metrics import r2_score
print("R2:", r2_score(y_test, y_pred))



# xg boost

import xgboost as xgb

model = xgb.XGBRegressor(
    n_estimators=500,
    max_depth=6,
    learning_rate=0.1,
    random_state=42
)

rf.fit(x_train, y_train)
y_pred = rf.predict(x_test)

from sklearn.metrics import r2_score
print("R2:", r2_score(y_test, y_pred))







